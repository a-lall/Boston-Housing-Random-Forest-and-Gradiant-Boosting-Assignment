{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boston Housing Study 2 (Python)**\n",
    "\n",
    "\n",
    "**This study uses data from the Boston Housing Study case as described in \"Marketing Data Science: Modeling Techniques for Predictive Analytics with R and Python\" (Miller 2015) to evaluate four regression modeling methodes, including Stochastic Gradient Descent, Lasso Regression, Random Forest, and Gradiant Boosting Regressor. An alternative version of Random forest and Gradiant Boosting Regressor with different hyperparameter settings are also included for comaprison purpose. These methods are evaluated within a 5-fold cross-validation design, using root mean-squared error (RMSE) as an index of prediction error.**\n",
    "\n",
    "**The results show that the performance of Random Forests and Gradient Boosting methods are highly impacted by their hyperparameter settings. They can either outperform or underperform SGD and Lasso, depending on the values assigned to hyperparameter(s). The better-performed Random Forest model and better_performed Gradient Boosting model are each applied to the full data set, with Gradient Boosting model reaches 1.0 perfect explained_variance score, outperforming Random Forest model. Therefore, Gradient Boosting method is the recommended method to use.**\n",
    "\n",
    "**Both Random Forest and Gradient Boosting methods indentified criminal as the most important feature in predicting house value. Age is recognized by both models as the second important explainatory variable in predicting house values.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Seed value for random number generators to obtain reproducible results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import base packages into the namespace for this program*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Read data for the Boston Housing Study*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_input = pd.read_csv('boston.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Drop neighborhood from the data being considered*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General description of the boston DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      "crim       506 non-null float64\n",
      "zn         506 non-null float64\n",
      "indus      506 non-null float64\n",
      "chas       506 non-null int64\n",
      "nox        506 non-null float64\n",
      "rooms      506 non-null float64\n",
      "age        506 non-null float64\n",
      "dis        506 non-null float64\n",
      "rad        506 non-null int64\n",
      "tax        506 non-null int64\n",
      "ptratio    506 non-null float64\n",
      "lstat      506 non-null float64\n",
      "mv         506 non-null float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 51.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "boston = boston_input.drop('neighborhood', 1)\n",
    "print('\\nGeneral description of the boston DataFrame:')\n",
    "print(boston.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptive statistics of the boston DataFrame:\n",
      "             crim          zn       indus        chas         nox       rooms  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
      "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
      "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
      "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "              age         dis         rad         tax     ptratio       lstat  \\\n",
      "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
      "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
      "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
      "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
      "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
      "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
      "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
      "\n",
      "               mv  \n",
      "count  506.000000  \n",
      "mean    22.528854  \n",
      "std      9.182176  \n",
      "min      5.000000  \n",
      "25%     17.025000  \n",
      "50%     21.200000  \n",
      "75%     25.000000  \n",
      "max     50.000000  \n"
     ]
    }
   ],
   "source": [
    "print('\\nDescriptive statistics of the boston DataFrame:')\n",
    "print(boston.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Set up preliminary data for data for fitting the models. Let the first column is the median housing value response, and the remaining columns are the explanatory variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelim_model_data = np.array([boston.mv,\\\n",
    "    boston.crim,\\\n",
    "    boston.zn,\\\n",
    "    boston.indus,\\\n",
    "    boston.chas,\\\n",
    "    boston.nox,\\\n",
    "    boston.rooms,\\\n",
    "    boston.age,\\\n",
    "    boston.dis,\\\n",
    "    boston.rad,\\\n",
    "    boston.tax,\\\n",
    "    boston.ptratio,\\\n",
    "    boston.lstat]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data dimensions: (506, 13)\n"
     ]
    }
   ],
   "source": [
    "print('\\nData dimensions:', prelim_model_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = prelim_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Set up the regression modeling methods: stochastic gradient descent, lasso Regression, random forest, and gradiant boosting regressor.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "names = [\"SDG\", \"Lasso\", \"RandomForest1\", \"RandomForest2\", \n",
    "         'GradientBoosting1', 'GradientBoosting2']\n",
    "classifiers = [SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1, \n",
    "                            random_state=RANDOM_SEED),\n",
    "               Lasso(alpha=0.1, random_state=RANDOM_SEED),\n",
    "               RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, \n",
    "                                     max_features = 4, random_state=RANDOM_SEED),\n",
    "               RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, n_jobs=-1, \n",
    "                                     max_features = 1, random_state=RANDOM_SEED),\n",
    "               GradientBoostingRegressor(max_depth=5, n_estimators=500, \n",
    "                                         learning_rate=0.1, random_state=RANDOM_SEED),\n",
    "               GradientBoostingRegressor(max_depth=5, n_estimators=500, \n",
    "                                         learning_rate=1.0, random_state=RANDOM_SEED)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Setup for calculating evaluation metric: RSME*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Specify the k-fold cross-validation design. n_folds is set to be 5. This is because typically, given these considerations, one performs k-fold cross-validation using k = 5 or k = 10, as these values have been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance. (James, Witten, Hastie, and Tibshirani, 2017)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "N_FOLDS = 5\n",
    "kf = KFold(n_splits = N_FOLDS, shuffle=False, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Set up numpy array for storing results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bbeb5c3a44bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "cv_results = np.zeros(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Considering the various scale of each varialbe, we will standardize the explantory variables on the train sets and then transform the test sets with the parameters learned from the train sets. Setup the standardization using sklearn.preprocessing.StandardScaler.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use the five specified methods to train on each fold of the train set and evaluate RMSE on each fold of test set. The results will be stored in cv_results.Codes reference: Miller, 2017 evaluate-classifiers-v001.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold index: 0 ------------------------------------------\n",
      "\n",
      "Fold index: 1 ------------------------------------------\n",
      "\n",
      "Fold index: 2 ------------------------------------------\n",
      "\n",
      "Fold index: 3 ------------------------------------------\n",
      "\n",
      "Fold index: 4 ------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "index_for_fold = 0 \n",
    "for train_index, test_index in kf.split(model_data):\n",
    "    print('\\nFold index:', index_for_fold,\n",
    "          '------------------------------------------')   \n",
    "    X_train_original = model_data[train_index, 0:model_data.shape[1]-1]\n",
    "    X_train = sc.fit_transform(X_train_original)\n",
    "    X_test_original = model_data[test_index, 0:model_data.shape[1]-1]\n",
    "    X_test = sc.transform (X_test_original)\n",
    "    y_train = model_data[train_index, model_data.shape[1]-1]\n",
    "    y_test = model_data[test_index, model_data.shape[1]-1]   \n",
    "    \n",
    "    index_for_method = 0 \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train, y_train) \n",
    "        y_test_predict = clf.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_test_predict)\n",
    "        rmse = sqrt(mse)\n",
    "        cv_results[index_for_fold, index_for_method] = rmse\n",
    "        index_for_method += 1\n",
    "  \n",
    "    index_for_fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "cv_results_df.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SDG     Lasso  RandomForest1  RandomForest2  GradientBoosting1  \\\n",
      "0  3.589419  3.569505       3.762934       4.248199           3.387930   \n",
      "1  4.243806  4.214762       3.590035       4.582711           3.209381   \n",
      "2  4.668449  4.261365       3.675043       4.074266           3.575690   \n",
      "3  4.823993  4.597577       4.097584       4.928922           4.495073   \n",
      "4  4.566410  4.266279       4.208358       4.429359           4.649866   \n",
      "\n",
      "   GradientBoosting2  \n",
      "0           3.762610  \n",
      "1           4.903872  \n",
      "2           3.946595  \n",
      "3           6.671067  \n",
      "4           5.149337  \n"
     ]
    }
   ],
   "source": [
    "print(cv_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "Average results from 5-fold cross-validation\n",
      "\n",
      "Method                 RMSE\n",
      "SDG                  4.378416\n",
      "Lasso                4.181898\n",
      "RandomForest1        3.866791\n",
      "RandomForest2        4.452691\n",
      "GradientBoosting1    3.863588\n",
      "GradientBoosting2    4.886696\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('\\n----------------------------------------------')\n",
    "print('Average results from ', N_FOLDS, '-fold cross-validation\\n',\n",
    "      '\\nMethod                 RMSE', sep = '')     \n",
    "print(cv_results_df.mean())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the performance of Random Forest and Gradient Boosting methods varies depending on their hyperparameters settings. In the case of Random Forest, the version with max_feature = 4 (log2(n), recommended by Müller and Guido) which beats Stochastic Gradient Descent AND Lasso Regression, significantly outperforms the one with max_feature = 1 which underperforms in comparison to Stochastic Gradient Descent and Lasso Regression. Similary, the version of Gradient Boosting with learning_rate = 0.1 outperforms both Stochastic Gradient Descent, Lasso Regression, while the version with learning_rate set to be 1.0 underperforms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Apply the better-performed Random Forest model to the full data set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data[:, 0:model_data.shape[1]-1]\n",
    "y = model_data[:, model_data.shape[1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = RandomForestRegressor(n_estimators=500, max_leaf_nodes=16, \n",
    "                            n_jobs=-1, max_features = 4, random_state=RANDOM_SEED)\n",
    "rnd.fit(X, y) \n",
    "y_predict = rnd.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate performance metrics: (1) explained variance score; (2) rmse*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "The RMSE of Random Forest Model is: 2.6807\n",
      "The explained variance score of Random Forest Model is: 0.8588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "\n",
    "mse_rnd = mean_squared_error(y, y_predict)\n",
    "rmse_rnd = sqrt(mse_rnd)\n",
    "evs = explained_variance_score(y, y_predict)  \n",
    "\n",
    "print('\\n----------------------------------------------')\n",
    "print('The RMSE of Random Forest Model is: {:.4f}'.format(rmse_rnd))     \n",
    "print('The explained variance score of Random Forest Model is: {:.4f}'.format(evs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the preferred Random Forest model to the full dataset, the RMSE is significantly improved in comparison to its performance on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calcualte feature_importance_score to identify variables that are important in predicting the home price*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.37953002 0.08412689 0.00201146 0.12246476 0.00346613 0.06168909\n",
      " 0.13552531 0.10805916 0.06185678 0.00349341 0.02723245 0.01054453]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(rnd.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Define function plot_feature_importances as demonstrated by Müller and Guido in Introduction to Machine Learning with Python (p77) to visualize the feature importance score of rnd model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_feature_importances(model, feature_name):\n",
    "    n_features = model_data.shape[1]-1\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), feature_name)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "names = ('crim', 'zn', 'indus', 'chas', 'nox', 'rooms', 'age', 'dis', \n",
    "         'rad', 'tax', 'ptratio', 'lstate')\n",
    "plot_feature_importances(rnd, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 3 leading explainatory variables identified by the Random Forest model are: crim, age, and chas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Apply the better-performed Gradient Boosting Regressing model to the full data set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(max_depth=5, n_estimators=500, \n",
    "                                learning_rate=0.1, random_state=RANDOM_SEED)\n",
    "gbr.fit(X, y) \n",
    "y_predict_1 = gbr.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calculate performance metrics: (1) explained variance score; (2) rmse*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------\n",
      "The RMSE of Gradient Boosting Regression Model is: 0.0377\n",
      "The explained variance score of Gradient BoostingRegression Model is: 1.0000\n"
     ]
    }
   ],
   "source": [
    "mse_gbr = mean_squared_error(y, y_predict_1)\n",
    "rmse_gbr = sqrt(mse_gbr)\n",
    "evs_gbr = explained_variance_score(y, y_predict_1)  \n",
    "\n",
    "print('\\n----------------------------------------------')\n",
    "print('The RMSE of Gradient Boosting Regression Model is: {:.4f}'.format(rmse_gbr))     \n",
    "print('The explained variance score of Gradient Boosting' \n",
    "      'Regression Model is: {:.4f}'.format(evs_gbr)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the preferred Gradient Boosting model to the full dataset, the RMSE is significantly improved in comparison to its performance on the test set. The model reached a perfect 1.0 explained variance score on the full data set. It outperforms the Random Forest model. Therefore, I will recommend the management to use Gradient Boosting method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Calcualte feature_importance_score to identify variables that are important in predicting the home price*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances of Gradient Boosting Regression Model:\n",
      "[6.32111496e-01 3.15261829e-02 5.35752505e-04 7.17299135e-03\n",
      " 2.95934672e-03 1.65044114e-02 1.92788980e-01 5.52784355e-02\n",
      " 4.16122245e-02 4.10332659e-03 7.03958428e-03 8.36726874e-03]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances of Gradient Boosting Regression Model:\\n{}\"\n",
    "      .format(gbr.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualize the feature_importance_score with pre-defined function.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_feature_importances(gbr, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 3 leading explainatory variables identified by the Gradient Boosting model are: crim, age, and dis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models identified crim as the most important indicator for housing value. Age is also recognized by both models as the second most import explainatory variable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
